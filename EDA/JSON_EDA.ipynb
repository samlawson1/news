{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_ex = 'CALIFORNIA'\n",
    "ex_path = os.path.join('DATA', state_ex, f'{state_ex}_page_8.json')\n",
    "f = open(ex_path, 'r')\n",
    "data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['abstract', 'web_url', 'snippet', 'lead_paragraph', 'print_section', 'print_page', 'source', 'multimedia', 'headline', 'keywords', 'pub_date', 'document_type', 'news_desk', 'section_name', 'byline', 'type_of_material', '_id', 'word_count', 'uri'])\n",
      "19\n",
      "dict_keys(['abstract', 'web_url', 'snippet', 'lead_paragraph', 'source', 'multimedia', 'headline', 'keywords', 'pub_date', 'document_type', 'news_desk', 'section_name', 'subsection_name', 'byline', 'type_of_material', '_id', 'word_count', 'uri'])\n",
      "18\n",
      "dict_keys(['abstract', 'web_url', 'snippet', 'lead_paragraph', 'print_section', 'print_page', 'source', 'multimedia', 'headline', 'keywords', 'pub_date', 'document_type', 'news_desk', 'section_name', 'byline', 'type_of_material', '_id', 'word_count', 'uri'])\n",
      "19\n",
      "dict_keys(['abstract', 'web_url', 'snippet', 'lead_paragraph', 'print_section', 'print_page', 'source', 'multimedia', 'headline', 'keywords', 'pub_date', 'document_type', 'news_desk', 'section_name', 'byline', 'type_of_material', '_id', 'word_count', 'uri'])\n",
      "19\n",
      "dict_keys(['abstract', 'web_url', 'snippet', 'lead_paragraph', 'print_section', 'print_page', 'source', 'multimedia', 'headline', 'keywords', 'pub_date', 'document_type', 'news_desk', 'section_name', 'byline', 'type_of_material', '_id', 'word_count', 'uri'])\n",
      "19\n",
      "dict_keys(['abstract', 'web_url', 'snippet', 'lead_paragraph', 'print_section', 'print_page', 'source', 'multimedia', 'headline', 'keywords', 'pub_date', 'document_type', 'news_desk', 'section_name', 'subsection_name', 'byline', 'type_of_material', '_id', 'word_count', 'uri'])\n",
      "20\n",
      "dict_keys(['abstract', 'web_url', 'snippet', 'lead_paragraph', 'print_section', 'print_page', 'source', 'multimedia', 'headline', 'keywords', 'pub_date', 'document_type', 'news_desk', 'section_name', 'byline', 'type_of_material', '_id', 'word_count', 'uri'])\n",
      "19\n",
      "dict_keys(['abstract', 'web_url', 'snippet', 'lead_paragraph', 'source', 'multimedia', 'headline', 'keywords', 'pub_date', 'document_type', 'news_desk', 'section_name', 'subsection_name', 'byline', 'type_of_material', '_id', 'word_count', 'uri'])\n",
      "18\n",
      "dict_keys(['abstract', 'web_url', 'snippet', 'lead_paragraph', 'source', 'multimedia', 'headline', 'keywords', 'pub_date', 'document_type', 'news_desk', 'section_name', 'byline', 'type_of_material', '_id', 'word_count', 'uri'])\n",
      "17\n",
      "dict_keys(['abstract', 'web_url', 'snippet', 'lead_paragraph', 'source', 'multimedia', 'headline', 'keywords', 'pub_date', 'document_type', 'news_desk', 'section_name', 'byline', 'type_of_material', '_id', 'word_count', 'uri'])\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    ex = data['response']['docs'][i].keys()\n",
    "    print(ex)\n",
    "    print(len(ex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'main': 'New Tools Pinpoint Natural Gas Leaks, Maximizing a Fuel’s Green Qualities',\n",
       " 'kicker': None,\n",
       " 'content_kicker': None,\n",
       " 'print_headline': 'New Tools Pinpoint Natural Gas Leaks, Maximizing a Fuel’s Green Qualities',\n",
       " 'name': None,\n",
       " 'seo': None,\n",
       " 'sub': None}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['response']['docs'][5]['headline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['abstract', 'web_url', 'snippet', 'lead_paragraph', 'print_section', 'print_page', 'source', 'multimedia', 'headline', 'keywords', 'pub_date', 'document_type', 'news_desk', 'section_name', 'subsection_name', 'byline', 'type_of_material', '_id', 'word_count', 'uri'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['response']['docs'][5].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create class for parsing the New York Times\n",
    "# Article Search API JSON Responses\n",
    "class NYT_JSON_Parse():\n",
    "\n",
    "    def __init__(self, json_response):\n",
    "        self.article_id = self.get_article_id(json_response)\n",
    "        self.article_facts = self.get_article_facts(json_response)\n",
    "        self.authors = self.get_article_authors(json_response)\n",
    "\n",
    "    def get_article_id(self, json_response):\n",
    "        #Get the id string in the resonse\n",
    "        id_string = json_response.get('_id')\n",
    "        #Output example:\n",
    "            # nyt://article/018efce9-c1d0-5966-9dce-d1b2fbb9e334\n",
    "            # Need to keep everything after the final /\n",
    "        #Find right index of /\n",
    "        i = id_string.rindex('/') + 1\n",
    "        id_out = id_string[i:]\n",
    "        return(id_out)\n",
    "    \n",
    "    def get_article_facts(self, json_response):\n",
    "        #Get facts for each article\n",
    "        # word count, number of authors, publication date, total subjects, etc.\n",
    "        # word count\n",
    "        word_count = int(json_response.get('word_count'))\n",
    "        #keywords\n",
    "        keyword_count = len(json_response.get('keywords'))\n",
    "        # number of authors\n",
    "        authors = int(len(json_response.get('byline')['person']))        \n",
    "        # publication_date\n",
    "        pub_date = pd.to_datetime(json_response.get('pub_date')).date()\n",
    "        # number of words in the headline\n",
    "        headline = json_response.get('headline')['main']\n",
    "        #Split whitespace to get each word and get the length of the resulting list\n",
    "        headline_words = len(headline.split(' '))\n",
    "        #See if the article was in print\n",
    "        if set(['print_section', 'print_page']).issubset(json_response.keys()) == True:\n",
    "            #If it was say so & get the page and section\n",
    "            in_print = True\n",
    "            print_page = int(json_response.get('print_page'))\n",
    "            print_section = json_response.get('print_section')\n",
    "        else:\n",
    "            #If not say so and set the page and section to None\n",
    "            in_print = False\n",
    "            print_page = None\n",
    "            print_section = None\n",
    "        #news_desk\n",
    "        news_desk_id_dict = {\n",
    "                        r'Adventure Sports':1, r'Arts & Leisure':2, r'Arts':3, r'Automobiles':4, r'Blogs':5,\n",
    "                        r'Books':6,r'Booming':7,r'Business Day':8,r'Business':9,r'Cars':10,r'Circuits':11,r'Classifieds':12,\n",
    "                        r'Connecticut':13,r'Crosswords & Games':14,r'Culture':15,r'DealBook':16,r'Dining':17,r'Editorial':18,\n",
    "                        r'Education':19,r'Energy':20,r'Entrepreneurs':21,r'Environment':22,r'Escapes':23,r'Fashion & Style':24,\n",
    "                        r'Fashion':25,r'Favorites':26,r'Financial':27,r'Flight':28,r'Food':29,r'Foreign':30,r'Generations':31,\n",
    "                        r'Giving':32,r'Global Home':33,r'Health & Fitness':34,r'Health':35,r'Home & Garden':36,r'Home':37,r'Jobs':38,\n",
    "                        r'Key':39,r'Letters':40,r'Long Island':41,r'Magazine':42,r'Market Place':43,r'Media':44,r\"Men's Health\":45,\n",
    "                        r'Metro':46,r'Metropolitan':47,r'Movies':48,r'Museums':49,r'National':50,r'Nesting':51,r'Obits':52,r'Obituaries':53,\n",
    "                        r'Obituary':54,r'OpEd':55,r'Opinion':56,r'Outlook':57,r'Personal Investing':58,r'Personal Tech':59,r'Play':60,r'Politics':61,\n",
    "                        r'Regionals':62,r'Retail':63,r'Retirement':64,r'Science':65,r'Small Business':66,r'Society':67,r'Sports':68,r'Style':69,r'Sunday Business':70,\n",
    "                        r'Sunday Review':71,r'Sunday Styles':72,r'T Magazine':73,r'T Style':74,r'Technology':75,\n",
    "                        r'Teens':76,r'Television':77,r'The Arts':78,r'The Business of Green':79,r'The City Desk':80,r'The City':81,\n",
    "                        r'The Marathon':82,r'The Millennium':83,r'The Natural World':84,r'The Upshot':85,r'The Weekend':86,r'The Year in Pictures':87,\n",
    "                        r'Theater':88,r'Then & Now':89,r'Thursday Styles':90,r'Times Topics':91,r'Travel':92,r'U.S.':93,\n",
    "                        r'Universal':94,r'Upshot':95,r'UrbanEye':96,r'Vacation':97,r'Washington':98,r'Wealth':99,r'Weather':100,\n",
    "                        r'Week in Review':101,r'Week':102,r'Weekend':103,r'Westchester':104,r'Wireless Living':105,r\"Women's Health\":106,\n",
    "                        r'Working':107,r'Workplace':108,r'World':109,r'Your Money':110\n",
    "                            }\n",
    "        if ('news_desk' in json_response.keys()) & (json_response.get('news_desk') not in ['', None]):\n",
    "            news_desk_str = json_response.get('news_desk')\n",
    "            news_desk_id = int(news_desk_id_dict.get(news_desk_str))\n",
    "        else:\n",
    "            news_desk_id = None\n",
    "        #Section Name\n",
    "        section_name_dict = {\n",
    "                        r'Arts':1,r'Automobiles':2,r'Autos':3,r'Blogs':4,r'Books':5,r'Booming':6,r'Business':7,r'Business Day':8,\n",
    "                        r'Corrections':9,r'Crosswords & Games':10,r'Crosswords/Games':11,r'Dining & Wine':12,r'Dining and Wine':13,r\"Editors Notes\":14,\n",
    "                        r'Education':15,r'Fashion & Style':16,r'Food':17,r'Front Page':18,r'Giving':19,r'Global Home':20,r'Great Homes & Destinations':21,\n",
    "                        r'Great Homes and Destinations':22,r'Health':23,r'Home & Garden':24,r'Home and Garden':25,r'International Home':26,\n",
    "                        r'Job Market':27,r'Learning':28,r'Magazine':29,r'Movies':30,r'Multimedia':31,r'Multimedia/Photos':32,r'N.Y. / Region':33,\n",
    "                        r'N.Y./Region':34,r'NYRegion':35,r'NYT Now':36,r'National':37,r'New York':38,r'New York and Region':39,\n",
    "                        r'Obituaries':40,r'Olympics':41,r'Open':42,r'Opinion':43,r'Paid Death Notices':44,r'Public Editor':45,r'Real Estate':46,r'Science':47,\n",
    "                        r'Sports':48,r'Style':49,r'Sunday Magazine':50,r'Sunday Review':51,r'T Magazine':52,r'T:Style':53,r'Technology':54,\n",
    "                        r'The Public Editor':55,r'The Upshot':56,r'Theater':57,r'Times Topics':58,r'TimesMachine':59,r\"Today's Headlines\":60,\n",
    "                        r'Topics':61,r'Travel':62,r'U.S.':63,r'Universal':64,r'UrbanEye':65,r'Washington':66,r'Week in Review':67,\n",
    "                        r'World':68,r'Your Money':69\n",
    "                            }\n",
    "        if 'section_name' in json_response.keys():\n",
    "            section_name_str = json_response.get('section_name')\n",
    "            section_id = section_name_dict.get(section_name_str)\n",
    "        else:\n",
    "            section_id = None\n",
    "        #article type\n",
    "        article_type_dict = {\n",
    "                        r'Addendum':1,r'An Analysis':2,r'An Appraisal':3,r'Archives':4,r'Article':5,r'Banner':6,r'Biography':7,\n",
    "                        r'Birth Notice':8,r'Blog':9,r'Brief':10,r'Caption':11,r'Chronology':12,r'Column':13,r'Correction':14,r'Economic Analysis':15,\n",
    "                        r'Editorial':16,r'Editorial Cartoon':17,r\"Editors' Note\":18,r'First Chapter':19,r'Front Page':20,r'Glossary':21,\n",
    "                        r'Interactive Feature':22,r'Interactive Graphic':23,r'Interview':24,r'Letter':25,r'List':26,r'Marriage Announcement':27,\n",
    "                        r'Military Analysis':28,r'News':29,r'News Analysis':30,r'Newsletter':31,r'Obituary':32,r'Obituary (Obit)':33,r'Op-Ed':34,\n",
    "                        r'Paid Death Notice':35,r'Postscript':36,r'Premium':37,r'Question':38,r'Quote':39,r'Recipe':40,r'Review':41,r'Schedule':42,\n",
    "                        r'SectionFront':43,r'Series':44,r'Slideshow':45,r'Special Report':46,r'Statistics':47,r'Summary':48,r'Text':49,r'Video':50,r'Web Log':51\n",
    "                            }\n",
    "        if 'type_of_material' in json_response.keys():\n",
    "            article_type_str = json_response.get('type_of_material')\n",
    "            article_type_id = article_type_dict.get(article_type_str)\n",
    "        else:\n",
    "            article_type_id = None\n",
    "        facts = (self.article_id, #primary key\n",
    "                 pub_date, \n",
    "                 word_count, \n",
    "                 keyword_count,\n",
    "                 authors, \n",
    "                 headline_words, \n",
    "                 in_print, \n",
    "                 print_page, \n",
    "                 print_section,\n",
    "                 news_desk_id,\n",
    "                 section_id,\n",
    "                 article_type_id,\n",
    "                 )\n",
    "        return(facts)\n",
    "    \n",
    "    def get_article_authors(self, json_response):\n",
    "        #Get the authors for each article\n",
    "        byline_authors = json_response.get('byline')['person']\n",
    "        if len(byline_authors) > 0:\n",
    "            authors = [\n",
    "                        (\n",
    "                            a.get('rank'), a.get('role'), a.get('firstname'), a.get('middlename'),  a.get('lastname'), a.get('qualifier')\n",
    "                        ) \n",
    "                            for a in byline_authors\n",
    "                            ]\n",
    "            return(authors)\n",
    "        else:\n",
    "            return(None)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'original': 'By Jim Robbins',\n",
       " 'person': [{'firstname': 'Jim',\n",
       "   'middlename': None,\n",
       "   'lastname': 'Robbins',\n",
       "   'qualifier': None,\n",
       "   'title': None,\n",
       "   'role': 'reported',\n",
       "   'organization': '',\n",
       "   'rank': 1}],\n",
       " 'organization': None}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['response']['docs'][0]['byline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a real number, not 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[155], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test \u001b[38;5;241m=\u001b[39m \u001b[43mNYT_JSON_Parse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresponse\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdocs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m test\u001b[38;5;241m.\u001b[39mauthors\n",
      "Cell \u001b[1;32mIn[152], line 7\u001b[0m, in \u001b[0;36mNYT_JSON_Parse.__init__\u001b[1;34m(self, json_response)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, json_response):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marticle_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_article_id(json_response)\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marticle_facts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_article_facts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_response\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauthors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_article_authors(json_response)\n",
      "Cell \u001b[1;32mIn[152], line 69\u001b[0m, in \u001b[0;36mNYT_JSON_Parse.get_article_facts\u001b[1;34m(self, json_response)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnews_desk\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m json_response\u001b[38;5;241m.\u001b[39mkeys()) \u001b[38;5;241m&\u001b[39m (json_response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnews_desk\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m]):\n\u001b[0;32m     68\u001b[0m     news_desk_str \u001b[38;5;241m=\u001b[39m json_response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnews_desk\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 69\u001b[0m     news_desk_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnews_desk_id_dict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnews_desk_str\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     71\u001b[0m     news_desk_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a real number, not 'NoneType'"
     ]
    }
   ],
   "source": [
    "test = NYT_JSON_Parse(data['response']['docs'][2])\n",
    "test.authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Business/Financial Desk'"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['response']['docs'][2]['news_desk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = [\n",
    "    (1, 2),\n",
    "    (3, 4)\n",
    "]\n",
    "\n",
    "second = [(5, 6)]\n",
    "\n",
    "third = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sam None'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'{'Sam'} {None}'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
