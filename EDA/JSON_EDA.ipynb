{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_ex = 'CALIFORNIA'\n",
    "ex_path = os.path.join('DATA', state_ex, f'{state_ex}_page_8.json')\n",
    "f = open(ex_path, 'r')\n",
    "data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['abstract', 'web_url', 'snippet', 'lead_paragraph', 'print_section', 'print_page', 'source', 'multimedia', 'headline', 'keywords', 'pub_date', 'document_type', 'news_desk', 'section_name', 'byline', 'type_of_material', '_id', 'word_count', 'uri'])\n",
      "19\n",
      "dict_keys(['abstract', 'web_url', 'snippet', 'lead_paragraph', 'source', 'multimedia', 'headline', 'keywords', 'pub_date', 'document_type', 'news_desk', 'section_name', 'subsection_name', 'byline', 'type_of_material', '_id', 'word_count', 'uri'])\n",
      "18\n",
      "dict_keys(['abstract', 'web_url', 'snippet', 'lead_paragraph', 'print_section', 'print_page', 'source', 'multimedia', 'headline', 'keywords', 'pub_date', 'document_type', 'news_desk', 'section_name', 'byline', 'type_of_material', '_id', 'word_count', 'uri'])\n",
      "19\n",
      "dict_keys(['abstract', 'web_url', 'snippet', 'lead_paragraph', 'print_section', 'print_page', 'source', 'multimedia', 'headline', 'keywords', 'pub_date', 'document_type', 'news_desk', 'section_name', 'byline', 'type_of_material', '_id', 'word_count', 'uri'])\n",
      "19\n",
      "dict_keys(['abstract', 'web_url', 'snippet', 'lead_paragraph', 'print_section', 'print_page', 'source', 'multimedia', 'headline', 'keywords', 'pub_date', 'document_type', 'news_desk', 'section_name', 'byline', 'type_of_material', '_id', 'word_count', 'uri'])\n",
      "19\n",
      "dict_keys(['abstract', 'web_url', 'snippet', 'lead_paragraph', 'print_section', 'print_page', 'source', 'multimedia', 'headline', 'keywords', 'pub_date', 'document_type', 'news_desk', 'section_name', 'subsection_name', 'byline', 'type_of_material', '_id', 'word_count', 'uri'])\n",
      "20\n",
      "dict_keys(['abstract', 'web_url', 'snippet', 'lead_paragraph', 'print_section', 'print_page', 'source', 'multimedia', 'headline', 'keywords', 'pub_date', 'document_type', 'news_desk', 'section_name', 'byline', 'type_of_material', '_id', 'word_count', 'uri'])\n",
      "19\n",
      "dict_keys(['abstract', 'web_url', 'snippet', 'lead_paragraph', 'source', 'multimedia', 'headline', 'keywords', 'pub_date', 'document_type', 'news_desk', 'section_name', 'subsection_name', 'byline', 'type_of_material', '_id', 'word_count', 'uri'])\n",
      "18\n",
      "dict_keys(['abstract', 'web_url', 'snippet', 'lead_paragraph', 'source', 'multimedia', 'headline', 'keywords', 'pub_date', 'document_type', 'news_desk', 'section_name', 'byline', 'type_of_material', '_id', 'word_count', 'uri'])\n",
      "17\n",
      "dict_keys(['abstract', 'web_url', 'snippet', 'lead_paragraph', 'source', 'multimedia', 'headline', 'keywords', 'pub_date', 'document_type', 'news_desk', 'section_name', 'byline', 'type_of_material', '_id', 'word_count', 'uri'])\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    ex = data['response']['docs'][i].keys()\n",
    "    print(ex)\n",
    "    print(len(ex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'main': 'New Tools Pinpoint Natural Gas Leaks, Maximizing a Fuel’s Green Qualities',\n",
       " 'kicker': None,\n",
       " 'content_kicker': None,\n",
       " 'print_headline': 'New Tools Pinpoint Natural Gas Leaks, Maximizing a Fuel’s Green Qualities',\n",
       " 'name': None,\n",
       " 'seo': None,\n",
       " 'sub': None}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['response']['docs'][5]['headline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'New Tools Pinpoint Natural Gas Leaks, Maximizing a Fuel’s Green Qualities'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['response']['docs'][5]['headline']['main']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create class for parsing the New York Times\n",
    "# Article Search API JSON Responses\n",
    "class NYT_JSON_Parse():\n",
    "\n",
    "    def __init__(self, json_response):\n",
    "        self.article_id = self.get_article_id(json_response)\n",
    "        self.article_facts = self.get_article_facts(json_response)\n",
    "\n",
    "    def get_article_id(self, json_response):\n",
    "        #Get the id string in the resonse\n",
    "        id_string = json_response.get('_id')\n",
    "        #Output example:\n",
    "            # nyt://article/018efce9-c1d0-5966-9dce-d1b2fbb9e334\n",
    "            # Need to keep everything after the final /\n",
    "        #Find right index of /\n",
    "        i = id_string.rindex('/') + 1\n",
    "        id_out = id_string[i:]\n",
    "        return(id_out)\n",
    "    \n",
    "    def get_article_facts(self, json_response):\n",
    "        #Get metrics for each article\n",
    "        # word count, number of authors, publication date, total subjects, etc.\n",
    "        # word count\n",
    "        word_count = int(json_response.get('word_count'))\n",
    "        # number of authors\n",
    "        authors = int(len(json_response.get('byline')['person']))\n",
    "        # publication_date\n",
    "        pub_date = pd.to_datetime(json_response.get('pub_date')).date()\n",
    "        # number of words in the headline\n",
    "        headline = json_response.get('headline')['main']\n",
    "        #Split whitespace to get each word and get the length of the resulting list\n",
    "        headline_words = len(headline.split(' '))\n",
    "        facts = (self.article_id, word_count, authors, headline_words)\n",
    "        return(facts)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('018efce9-c1d0-5966-9dce-d1b2fbb9e334', 1038, 1, 11)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = NYT_JSON_Parse(data['response']['docs'][5])\n",
    "test.article_facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'firstname': 'Matthew',\n",
       "  'middlename': 'L.',\n",
       "  'lastname': 'Wald',\n",
       "  'qualifier': None,\n",
       "  'title': None,\n",
       "  'role': 'reported',\n",
       "  'organization': '',\n",
       "  'rank': 1}]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['response']['docs'][5]['byline']['person']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
